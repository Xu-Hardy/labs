---
title:  Amazon Bedrock Python SDK 完成视频风格迁移
---

在这部分演示中，我们将使用 Amazon Bedrock Stability.ai Stable Diffusion XL 1.0 模型创建视频动画。高级流程如下：

1. 选择一个视频并复制到 source_videos 子目录中
2. 使用 FFmpeg 将视频分割为单独的帧（JPEG 图像）
3. 选择要设置动画的一系列连续帧并将其复制到新目录
4. 使用之前的图像到图像的方法，循环遍历原始帧的目录并生成新的帧
5. 检查生成的帧是否存在异常并删除任何不需要的帧
6. 使用 FFmpeg 将生成的帧重新组合成视频动画(Gif或者MP4)

```python
import ffmpeg
import base64
import io
from enum import Enum, unique
import json
import logging
import boto3
from PIL import Image
import time
import os
from botocore.exceptions import ClientError

os.environ["AWS_PROFILE"]="g"


SOURCE_IMAGES = "./source/img"
SOURCE_VIDEOS = "source/videos"
SOURCE_FRAMES = "./source/frames"

GENERATED_IMAGES = "./generate/img"
GENERATED_FRAMES = "./generate/frames"
GENERATED_VIDEOS = "./generate/videos"

video_name = "red_squirrel.mp4"

MODEL_ID = "stability.stable-diffusion-xl-v1"
SOURCE_VIDEO = f"{SOURCE_VIDEOS}/{video_name}"
SOURCE_VIDEO_FRAMES = f"{SOURCE_FRAMES}/{video_name}"
GENERATED_VIDEO_FRAMES = f"{GENERATED_FRAMES}/{video_name}"
GENERATED_VIDEO = f"{GENERATED_VIDEOS}/{video_name}"

if not os.path.exists(SOURCE_VIDEO_FRAMES):
    os.makedirs(SOURCE_VIDEO_FRAMES)
if not os.path.exists(GENERATED_VIDEO_FRAMES):
    os.makedirs(GENERATED_VIDEO_FRAMES)


# Set up logging for notebook environment
logger = logging.getLogger(__name__)
if logger.hasHandlers():
    logger.handlers.clear()
handler = logging.StreamHandler()
logger.addHandler(handler)
formatter = logging.Formatter("%(asctime)s - %(levelname)s - %(message)s")
handler.setFormatter(formatter)
logger.setLevel(logging.INFO)

class ImageToImageRequest:
    """
    Class for handling image to image request parameters.
    """

    def __init__(
        self,
        image_width,
        image_height,
        positive_prompt,
        negative_prompt,
        init_image_mode="IMAGE_STRENGTH",
        image_strength=0.5,
        cfg_scale=7,
        clip_guidance_preset="SLOWER",
        sampler="K_DPMPP_2M",
        samples=1,
        seed=1,
        steps=30,
        style_preset="photographic",
        extras=None,
    ):
        self.image_width = image_width
        self.image_height = image_height
        self.positive_prompt = positive_prompt
        self.negative_prompt = negative_prompt
        self.init_image_mode = init_image_mode
        self.image_strength = image_strength
        self.cfg_scale = cfg_scale
        self.clip_guidance_preset = clip_guidance_preset
        self.sampler = sampler
        self.samples = samples
        self.seed = seed
        self.steps = steps
        self.style_preset = style_preset
        self.extras = extras


@unique
class StylesPresets(Enum):
    """
    Enumerator for SDXL style presets.
    """

    THREE_D_MODEL = "3d-model"
    ANALOG_FILM = "analog-film"
    ANIME = "anime"
    CINEMATIC = "cinematic"
    COMIC_BOOK = "comic-book"
    DIGITAL_ART = "digital-art"
    ENHANCE = "enhance"
    FANTASY_ART = "fantasy-art"
    ISOMETRIC = "isometric"
    LINE_ART = "line-art"
    LOW_POLY = "low-poly"
    MODELING_COMPOUND = "modeling-compound"
    NEON_PUNK = "neon-punk"
    ORIGAMI = "origami"
    PHOTOGRAPHIC = "photographic"
    PIXEL_ART = "pixel-art"
    TILE_TEXTURE = "tile-texture"


class ImageError(Exception):
    """
    Custom exception for errors returned by SDXL 1.0.
    """

    def __init__(self, message):
        self.message = message

def image_to_image_request(
    imageToImageRequest,
    source_image,
    generated_images,
):
    """
    Entrypoint for SDXL example.
    Args:
        imageToImageRequest (ImageToImageRequest): The image to image request to use.
        generated_images (str): The directory to save the generated images to.
        source_image (str): The source image to use.
    """

    # Read source image from file and encode as base64 strings
    image = Image.open(source_image)
    new_image = image.resize(
        (imageToImageRequest.image_width, imageToImageRequest.image_height)
    )

    new_image.save(f"{source_image[:-4]}_tmp.jpg")

    with open(f"{source_image[:-4]}_tmp.jpg", "rb") as image_file:
        init_image = base64.b64encode(image_file.read()).decode("utf8")

    # Build request body
    body = json.dumps(
        {
            "text_prompts": [
                {"text": imageToImageRequest.positive_prompt, "weight": 1},
                {"text": imageToImageRequest.negative_prompt, "weight": -1},
            ],
            "init_image": init_image,
            "init_image_mode": imageToImageRequest.init_image_mode,
            "image_strength": imageToImageRequest.image_strength,
            "cfg_scale": imageToImageRequest.cfg_scale,
            "clip_guidance_preset": imageToImageRequest.clip_guidance_preset,
            "sampler": imageToImageRequest.sampler,
            "samples": imageToImageRequest.samples,
            "seed": imageToImageRequest.seed,
            "steps": imageToImageRequest.steps,
            "style_preset": imageToImageRequest.style_preset,
        }
    )

    try:
        logger.info(f"Source image: {source_image}")
        image_bytes = generate_image_from_image(model_id=MODEL_ID, body=body)
        image = Image.open(io.BytesIO(image_bytes))
        epoch_time = int(time.time())
        # generated_image_path = f"{generated_images}/image_{epoch_time}.jpg"
        generated_image_path = f"{GENERATED_VIDEO_FRAMES}/image_{epoch_time}_{imageToImageRequest.seed}_{imageToImageRequest.sampler}_{imageToImageRequest.image_strength}_{imageToImageRequest.cfg_scale}_{imageToImageRequest.steps}_{imageToImageRequest.style_preset}.jpg"
        logger.info(f"Generated image: {generated_image_path}")
        # https://pillow.readthedocs.io/en/stable/handbook/image-file-formats.html#png
        # image.save(generated_image_path, format="PNG", compress_level=1)
        # https://pillow.readthedocs.io/en/stable/handbook/image-file-formats.html#jpeg-saving
        image.save(generated_image_path, format="JPEG", quality=95)

    except ClientError as err:
        message = err.response["Error"]["Message"]
        logger.error("A client error occurred: %s", message)
    except ImageError as err:
        logger.error(err.message)

    else:
        logger.info(f"Finished generating image with SDXL model {MODEL_ID}.")

def generate_image_from_image(model_id, body):
    """
    Generate an image using SDXL 1.0 on demand.
    Args:
        model_id (str): The model ID to use.
        body (str) : The request body to use.
    Returns:
        image_bytes (bytes): The image generated by the model.
    """

    logger.info("Generating image with SDXL model %s", model_id)

    bedrock = boto3.client(service_name="bedrock-runtime")

    accept = "application/json"
    content_type = "application/json"

    response = bedrock.invoke_model(
        body=body, modelId=model_id, accept=accept, contentType=content_type
    )
    response_body = json.loads(response.get("body").read())
    logger.info(f"Bedrock result: {response_body['result']}")

    base64_image = response_body.get("artifacts")[0].get("base64")
    base64_bytes = base64_image.encode("ascii")
    image_bytes = base64.b64decode(base64_bytes)

    finish_reason = response_body.get("artifacts")[0].get("finishReason")

    if finish_reason == "ERROR" or finish_reason == "CONTENT_FILTERED":
        raise ImageError(f"Image generation error. Error code is {finish_reason}")

    logger.info("Successfully generated image with the SDXL 1.0 model %s", model_id)

    return image_bytes
# step1
(
    ffmpeg.input(
        SOURCE_VIDEO,
    )
    .output(
        f"{SOURCE_VIDEO_FRAMES}/frame%d.jpg",
        start_number=1,
        qscale=5,
    )
    .overwrite_output()
    .run(quiet=False)
)

POSITIVE_PROMPT = "red squirrel with red eyes, in the style of Pixar animation"
NEGATIVE_PROMPT = "out of frame, lowres, text, error, cropped, worst quality, low quality, jpeg artifacts, ugly, duplicate, morbid, mutilated, out of frame, extra fingers, mutated hands, poorly drawn hands, poorly drawn face, mutation, deformed, blurry, bad anatomy, bad proportions, extra limbs, cloned face, disfigured, gross proportions, malformed limbs, missing arms, missing legs, extra arms, extra legs, fused fingers, too many fingers, long neck, username, watermark, signature"


# Maximum resolution for SDXL v1.0 is 1,048,576 pixels/frame (e.g., 1024 x 1024)
# Pixel width and height of the image to generate must be a multiple of 64
# Current video frames: 1280 W x 720 H = 921,600 pixels
# 1280/64 = 20
# 720/64 = 11.25 > 11

imageToImageRequest = ImageToImageRequest(
    image_width=(20 * 64),
    image_height=(11 * 64),
    positive_prompt=POSITIVE_PROMPT,
    negative_prompt=NEGATIVE_PROMPT,
    init_image_mode="IMAGE_STRENGTH",
    image_strength=0.4,
    cfg_scale=15,
    clip_guidance_preset="SLOWEST",
    sampler="K_DPMPP_2M",  # DPM++ 2M Karras (https://stable-diffusion-art.com/samplers/)
    samples=1,
    seed=123234343,
    steps=25,
    style_preset=StylesPresets.ANIME.value,
    extras=None,
)

# Loop through all the frames in the source video or a selection of frames
for i in range(160, 200, 2):
    image_to_image_request(
        imageToImageRequest,
        f"{SOURCE_VIDEO_FRAMES}/frame{i}.jpg",
        GENERATED_VIDEO_FRAMES,
    )



(
    ffmpeg.input(
        f"{GENERATED_VIDEO_FRAMES}/*.jpg",
        pattern_type="glob",
        framerate=9,
    )
    .output(f"{GENERATED_VIDEO}")
    .run(overwrite_output=True)
)
```


